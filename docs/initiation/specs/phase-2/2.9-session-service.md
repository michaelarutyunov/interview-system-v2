# Spec 2.9: Session Service

## Objective
Create the session service that orchestrates the complete turn processing pipeline.

## Context
- Reference: PRD Section 4.1 (Interview Conduction flow), Section 8.6 (Turn Response)
- v1 Reference: `src/modules/session_orchestrator.py`
- Orchestrates: extraction → graph update → question generation
- This is the core "brain" of the interview system

## Input Files
- `src/services/extraction_service.py` - From spec 2.4
- `src/services/graph_service.py` - From spec 2.6
- `src/services/question_service.py` - From spec 2.8
- `src/persistence/repositories/session_repo.py` - From Phase 1
- `PRD.md` - Section 8.6 (Turn Response structure)
- v1: `/home/mikhailarutyunov/projects/graph-enabled-ai-interviewer/src/modules/session_orchestrator.py`

## Output Files

### src/services/session_service.py
```python
"""
Session orchestration service.

Orchestrates the complete turn processing pipeline:
1. Save user utterance
2. Extract concepts and relationships
3. Update knowledge graph
4. Compute graph state
5. Select strategy (Phase 2: hardcoded "deepen")
6. Generate follow-up question
7. Save system utterance
8. Return TurnResult

This is the main entry point for interview turn processing.
"""

from dataclasses import dataclass, field
from datetime import datetime
from typing import Optional, List, Dict, Any
from uuid import uuid4

import structlog

from src.domain.models.extraction import ExtractionResult
from src.domain.models.knowledge_graph import GraphState, KGNode
from src.domain.models.utterance import Utterance
from src.services.extraction_service import ExtractionService
from src.services.graph_service import GraphService
from src.services.question_service import QuestionService
from src.persistence.repositories.session_repo import SessionRepository
from src.persistence.repositories.graph_repo import GraphRepository

log = structlog.get_logger(__name__)


@dataclass
class TurnResult:
    """
    Result of processing a single turn.

    Matches PRD Section 8.6 response structure.
    """
    turn_number: int
    extracted: Dict[str, Any]  # concepts, relationships
    graph_state: Dict[str, Any]  # node_count, edge_count, depth_achieved
    scoring: Dict[str, float]  # coverage, depth, saturation (Phase 3)
    strategy_selected: str
    next_question: str
    should_continue: bool
    latency_ms: int = 0


@dataclass
class SessionContext:
    """
    Context for current session state.

    Loaded at turn start, used throughout pipeline.
    """
    session_id: str
    methodology: str
    concept_id: str
    concept_name: str
    turn_number: int
    recent_utterances: List[Dict[str, str]] = field(default_factory=list)
    graph_state: Optional[GraphState] = None
    recent_nodes: List[KGNode] = field(default_factory=list)


class SessionService:
    """
    Orchestrates interview session turn processing.

    Main entry point for processing user input and generating responses.
    """

    def __init__(
        self,
        session_repo: SessionRepository,
        graph_repo: GraphRepository,
        extraction_service: Optional[ExtractionService] = None,
        graph_service: Optional[GraphService] = None,
        question_service: Optional[QuestionService] = None,
        max_turns: int = 20,
        target_coverage: float = 0.8,
    ):
        """
        Initialize session service.

        Args:
            session_repo: Session repository
            graph_repo: Graph repository
            extraction_service: Extraction service (creates default if None)
            graph_service: Graph service (creates default if None)
            question_service: Question service (creates default if None)
            max_turns: Maximum turns before forcing close
            target_coverage: Coverage target (Phase 3)
        """
        self.session_repo = session_repo
        self.graph_repo = graph_repo

        # Create services with graph_repo where needed
        self.extraction = extraction_service or ExtractionService()
        self.graph = graph_service or GraphService(graph_repo)
        self.question = question_service or QuestionService()

        self.max_turns = max_turns
        self.target_coverage = target_coverage

        log.info("session_service_initialized", max_turns=max_turns)

    async def process_turn(
        self,
        session_id: str,
        user_input: str,
    ) -> TurnResult:
        """
        Process a single interview turn.

        Pipeline:
        1. Load session context
        2. Save user utterance
        3. Extract concepts/relationships
        4. Update knowledge graph
        5. Compute graph state
        6. Select strategy (Phase 2: hardcoded)
        7. Generate follow-up question
        8. Save system utterance
        9. Return TurnResult

        Args:
            session_id: Session ID
            user_input: User's response text

        Returns:
            TurnResult with extraction, graph state, next question

        Raises:
            ValueError: If session not found
        """
        import time
        start_time = time.perf_counter()

        log.info("processing_turn", session_id=session_id, input_length=len(user_input))

        # Step 1: Load session context
        context = await self._load_context(session_id)

        # Step 2: Save user utterance
        user_utterance = await self._save_utterance(
            session_id=session_id,
            turn_number=context.turn_number,
            speaker="user",
            text=user_input,
        )

        # Step 3: Extract concepts/relationships
        extraction = await self.extraction.extract(
            text=user_input,
            context=self._format_context_for_extraction(context),
        )

        # Step 4: Update knowledge graph
        nodes, edges = await self.graph.add_extraction_to_graph(
            session_id=session_id,
            extraction=extraction,
            utterance_id=user_utterance.id,
        )

        # Step 5: Compute graph state
        graph_state = await self.graph.get_graph_state(session_id)
        recent_nodes = await self.graph.get_recent_nodes(session_id, limit=5)

        # Step 6: Select strategy (Phase 2: hardcoded "deepen")
        strategy = self._select_strategy(
            graph_state=graph_state,
            turn_number=context.turn_number,
            extraction=extraction,
        )

        # Step 7: Determine if we should continue
        should_continue = self._should_continue(
            turn_number=context.turn_number,
            graph_state=graph_state,
            strategy=strategy,
        )

        # Step 8: Generate follow-up question
        if should_continue:
            focus_concept = self.question.select_focus_concept(
                recent_nodes=recent_nodes,
                graph_state=graph_state,
                strategy=strategy,
            )

            # Add current utterance to recent for context
            updated_utterances = context.recent_utterances + [
                {"speaker": "user", "text": user_input}
            ]

            next_question = await self.question.generate_question(
                focus_concept=focus_concept,
                recent_utterances=updated_utterances,
                graph_state=graph_state,
                recent_nodes=recent_nodes,
                strategy=strategy,
            )
        else:
            next_question = "Thank you for sharing your thoughts with me today. This has been very helpful."

        # Step 9: Save system utterance
        await self._save_utterance(
            session_id=session_id,
            turn_number=context.turn_number,
            speaker="system",
            text=next_question,
        )

        # Step 10: Update session turn count
        await self.session_repo.update(
            session_id,
            turn_count=context.turn_number + 1,
            updated_at=datetime.utcnow(),
        )

        latency_ms = int((time.perf_counter() - start_time) * 1000)

        log.info(
            "turn_processed",
            session_id=session_id,
            turn_number=context.turn_number,
            concepts_extracted=len(extraction.concepts),
            strategy=strategy,
            should_continue=should_continue,
            latency_ms=latency_ms,
        )

        return TurnResult(
            turn_number=context.turn_number,
            extracted={
                "concepts": [
                    {
                        "text": c.text,
                        "type": c.node_type,
                        "confidence": c.confidence,
                    }
                    for c in extraction.concepts
                ],
                "relationships": [
                    {
                        "source": r.source_text,
                        "target": r.target_text,
                        "type": r.relationship_type,
                    }
                    for r in extraction.relationships
                ],
            },
            graph_state={
                "node_count": graph_state.node_count,
                "edge_count": graph_state.edge_count,
                "depth_achieved": graph_state.nodes_by_type,
            },
            scoring={
                "coverage": 0.0,  # Phase 3
                "depth": 0.0,  # Phase 3
                "saturation": 0.0,  # Phase 3
            },
            strategy_selected=strategy,
            next_question=next_question,
            should_continue=should_continue,
            latency_ms=latency_ms,
        )

    async def start_session(
        self,
        session_id: str,
    ) -> str:
        """
        Generate opening question for a session.

        Args:
            session_id: Session ID

        Returns:
            Opening question string
        """
        session = await self.session_repo.get(session_id)
        if not session:
            raise ValueError(f"Session {session_id} not found")

        # Get concept name from config
        concept_name = session.config.get("concept_name", "the product")
        concept_description = session.config.get("concept_description", "")

        question = await self.question.generate_opening_question(
            concept_name=concept_name,
            concept_description=concept_description,
        )

        # Save as system utterance (turn 0)
        await self._save_utterance(
            session_id=session_id,
            turn_number=0,
            speaker="system",
            text=question,
        )

        log.info("session_started", session_id=session_id, concept=concept_name)

        return question

    async def _load_context(self, session_id: str) -> SessionContext:
        """
        Load session context for turn processing.

        Args:
            session_id: Session ID

        Returns:
            SessionContext with current state
        """
        session = await self.session_repo.get(session_id)
        if not session:
            raise ValueError(f"Session {session_id} not found")

        # Get recent utterances
        recent_utterances = await self._get_recent_utterances(session_id, limit=10)

        # Get graph state
        graph_state = await self.graph.get_graph_state(session_id)

        # Get recent nodes
        recent_nodes = await self.graph.get_recent_nodes(session_id, limit=5)

        return SessionContext(
            session_id=session_id,
            methodology=session.methodology,
            concept_id=session.concept_id,
            concept_name=session.config.get("concept_name", ""),
            turn_number=session.turn_count or 1,
            recent_utterances=recent_utterances,
            graph_state=graph_state,
            recent_nodes=recent_nodes,
        )

    async def _save_utterance(
        self,
        session_id: str,
        turn_number: int,
        speaker: str,
        text: str,
    ) -> Utterance:
        """
        Save an utterance to the database.

        Args:
            session_id: Session ID
            turn_number: Turn number
            speaker: "user" or "system"
            text: Utterance text

        Returns:
            Created Utterance
        """
        utterance_id = str(uuid4())
        now = datetime.utcnow().isoformat()

        # Insert into utterances table
        await self.session_repo.db.execute(
            """
            INSERT INTO utterances (id, session_id, turn_number, speaker, text, discourse_markers, created_at)
            VALUES (?, ?, ?, ?, ?, ?, ?)
            """,
            (utterance_id, session_id, turn_number, speaker, text, "[]", now),
        )
        await self.session_repo.db.commit()

        return Utterance(
            id=utterance_id,
            session_id=session_id,
            turn_number=turn_number,
            speaker=speaker,
            text=text,
        )

    async def _get_recent_utterances(
        self, session_id: str, limit: int = 10
    ) -> List[Dict[str, str]]:
        """
        Get recent utterances for context.

        Args:
            session_id: Session ID
            limit: Max utterances to return

        Returns:
            List of {"speaker": str, "text": str} dicts
        """
        cursor = await self.session_repo.db.execute(
            """
            SELECT speaker, text FROM utterances
            WHERE session_id = ?
            ORDER BY turn_number DESC, created_at DESC
            LIMIT ?
            """,
            (session_id, limit),
        )
        rows = await cursor.fetchall()

        # Reverse to get chronological order
        return [{"speaker": row[0], "text": row[1]} for row in reversed(rows)]

    def _format_context_for_extraction(self, context: SessionContext) -> str:
        """
        Format context for extraction prompt.

        Args:
            context: Session context

        Returns:
            Context string
        """
        if not context.recent_utterances:
            return ""

        lines = []
        for utt in context.recent_utterances[-5:]:
            speaker = "Respondent" if utt["speaker"] == "user" else "Interviewer"
            lines.append(f"{speaker}: {utt['text']}")

        return "\n".join(lines)

    def _select_strategy(
        self,
        graph_state: GraphState,
        turn_number: int,
        extraction: ExtractionResult,
    ) -> str:
        """
        Select questioning strategy.

        Phase 2: Always returns "deepen"
        Phase 3: Full scoring-based selection

        Args:
            graph_state: Current graph state
            turn_number: Current turn number
            extraction: Latest extraction result

        Returns:
            Strategy name
        """
        # Phase 2: Hardcoded deepen
        # Phase 3 will implement full scoring/arbitration

        # Simple heuristics for variety
        if turn_number >= self.max_turns - 2:
            return "close"

        # Default to deepen
        return "deepen"

    def _should_continue(
        self,
        turn_number: int,
        graph_state: GraphState,
        strategy: str,
    ) -> bool:
        """
        Determine if interview should continue.

        Args:
            turn_number: Current turn number
            graph_state: Current graph state
            strategy: Selected strategy

        Returns:
            True if should continue, False if should end
        """
        # Max turns reached
        if turn_number >= self.max_turns:
            log.info("session_ending", reason="max_turns")
            return False

        # Strategy is close
        if strategy == "close":
            log.info("session_ending", reason="close_strategy")
            return False

        # Phase 3 will add: coverage target reached, saturation detected

        return True
```

### tests/unit/test_session_service.py
```python
"""Tests for session service."""

import pytest
from unittest.mock import AsyncMock, MagicMock, patch
from datetime import datetime

from src.services.session_service import SessionService, TurnResult, SessionContext
from src.domain.models.extraction import ExtractionResult, ExtractedConcept
from src.domain.models.knowledge_graph import GraphState, KGNode


@pytest.fixture
def mock_session_repo():
    """Create mock session repository."""
    repo = AsyncMock()
    repo.db = AsyncMock()
    repo.db.execute = AsyncMock()
    repo.db.commit = AsyncMock()
    return repo


@pytest.fixture
def mock_graph_repo():
    """Create mock graph repository."""
    return AsyncMock()


@pytest.fixture
def mock_extraction_service():
    """Create mock extraction service."""
    service = AsyncMock()
    service.extract = AsyncMock(return_value=ExtractionResult(
        concepts=[ExtractedConcept(text="test", node_type="attribute")],
        relationships=[],
        is_extractable=True,
    ))
    return service


@pytest.fixture
def mock_graph_service():
    """Create mock graph service."""
    service = AsyncMock()
    service.add_extraction_to_graph = AsyncMock(return_value=([], []))
    service.get_graph_state = AsyncMock(return_value=GraphState(
        node_count=1, edge_count=0, nodes_by_type={"attribute": 1}
    ))
    service.get_recent_nodes = AsyncMock(return_value=[
        KGNode(id="n1", session_id="s1", label="test", node_type="attribute")
    ])
    return service


@pytest.fixture
def mock_question_service():
    """Create mock question service."""
    service = AsyncMock()
    service.generate_question = AsyncMock(return_value="Why is that important?")
    service.generate_opening_question = AsyncMock(return_value="What do you think?")
    service.select_focus_concept = MagicMock(return_value="test")
    return service


@pytest.fixture
def service(
    mock_session_repo,
    mock_graph_repo,
    mock_extraction_service,
    mock_graph_service,
    mock_question_service,
):
    """Create session service with mocks."""
    return SessionService(
        session_repo=mock_session_repo,
        graph_repo=mock_graph_repo,
        extraction_service=mock_extraction_service,
        graph_service=mock_graph_service,
        question_service=mock_question_service,
    )


@pytest.fixture
def mock_session():
    """Create mock session object."""
    session = MagicMock()
    session.id = "test-session"
    session.methodology = "means_end_chain"
    session.concept_id = "test-concept"
    session.config = {"concept_name": "Test Product"}
    session.turn_count = 1
    return session


class TestProcessTurn:
    """Tests for process_turn."""

    @pytest.mark.asyncio
    async def test_returns_turn_result(
        self, service, mock_session_repo, mock_session
    ):
        """process_turn returns TurnResult."""
        mock_session_repo.get = AsyncMock(return_value=mock_session)

        # Mock utterance fetching
        cursor = AsyncMock()
        cursor.fetchall = AsyncMock(return_value=[])
        mock_session_repo.db.execute = AsyncMock(return_value=cursor)

        result = await service.process_turn(
            session_id="test-session",
            user_input="I like the taste",
        )

        assert isinstance(result, TurnResult)
        assert result.turn_number == 1
        assert result.strategy_selected == "deepen"
        assert result.should_continue is True

    @pytest.mark.asyncio
    async def test_calls_extraction(
        self, service, mock_session_repo, mock_session, mock_extraction_service
    ):
        """Calls extraction service with user input."""
        mock_session_repo.get = AsyncMock(return_value=mock_session)
        cursor = AsyncMock()
        cursor.fetchall = AsyncMock(return_value=[])
        mock_session_repo.db.execute = AsyncMock(return_value=cursor)

        await service.process_turn("s1", "I like the taste")

        mock_extraction_service.extract.assert_called_once()
        call_args = mock_extraction_service.extract.call_args
        assert call_args.kwargs["text"] == "I like the taste"

    @pytest.mark.asyncio
    async def test_updates_graph(
        self, service, mock_session_repo, mock_session, mock_graph_service
    ):
        """Updates graph with extraction results."""
        mock_session_repo.get = AsyncMock(return_value=mock_session)
        cursor = AsyncMock()
        cursor.fetchall = AsyncMock(return_value=[])
        mock_session_repo.db.execute = AsyncMock(return_value=cursor)

        await service.process_turn("s1", "I like it")

        mock_graph_service.add_extraction_to_graph.assert_called_once()

    @pytest.mark.asyncio
    async def test_generates_question(
        self, service, mock_session_repo, mock_session, mock_question_service
    ):
        """Generates follow-up question."""
        mock_session_repo.get = AsyncMock(return_value=mock_session)
        cursor = AsyncMock()
        cursor.fetchall = AsyncMock(return_value=[])
        mock_session_repo.db.execute = AsyncMock(return_value=cursor)

        result = await service.process_turn("s1", "I like it")

        mock_question_service.generate_question.assert_called_once()
        assert result.next_question == "Why is that important?"

    @pytest.mark.asyncio
    async def test_ends_at_max_turns(
        self, service, mock_session_repo, mock_session
    ):
        """Ends session at max turns."""
        mock_session.turn_count = 20  # At max
        mock_session_repo.get = AsyncMock(return_value=mock_session)
        cursor = AsyncMock()
        cursor.fetchall = AsyncMock(return_value=[])
        mock_session_repo.db.execute = AsyncMock(return_value=cursor)

        result = await service.process_turn("s1", "I like it")

        assert result.should_continue is False


class TestStartSession:
    """Tests for start_session."""

    @pytest.mark.asyncio
    async def test_generates_opening(
        self, service, mock_session_repo, mock_session, mock_question_service
    ):
        """start_session generates opening question."""
        mock_session_repo.get = AsyncMock(return_value=mock_session)

        question = await service.start_session("test-session")

        assert question == "What do you think?"
        mock_question_service.generate_opening_question.assert_called_once()

    @pytest.mark.asyncio
    async def test_raises_for_unknown_session(self, service, mock_session_repo):
        """Raises ValueError for unknown session."""
        mock_session_repo.get = AsyncMock(return_value=None)

        with pytest.raises(ValueError, match="not found"):
            await service.start_session("unknown")


class TestStrategySelection:
    """Tests for strategy selection."""

    def test_returns_close_near_max_turns(self, service):
        """Returns close strategy near max turns."""
        strategy = service._select_strategy(
            graph_state=GraphState(),
            turn_number=19,  # Near max of 20
            extraction=ExtractionResult(),
        )

        assert strategy == "close"

    def test_returns_deepen_by_default(self, service):
        """Returns deepen by default (Phase 2)."""
        strategy = service._select_strategy(
            graph_state=GraphState(),
            turn_number=5,
            extraction=ExtractionResult(),
        )

        assert strategy == "deepen"


class TestShouldContinue:
    """Tests for should_continue."""

    def test_false_at_max_turns(self, service):
        """Returns False at max turns."""
        result = service._should_continue(
            turn_number=20,
            graph_state=GraphState(),
            strategy="deepen",
        )

        assert result is False

    def test_false_for_close_strategy(self, service):
        """Returns False for close strategy."""
        result = service._should_continue(
            turn_number=5,
            graph_state=GraphState(),
            strategy="close",
        )

        assert result is False

    def test_true_normally(self, service):
        """Returns True for normal conditions."""
        result = service._should_continue(
            turn_number=5,
            graph_state=GraphState(),
            strategy="deepen",
        )

        assert result is True
```

## Requirements
1. Must orchestrate: extraction → graph → question services
2. Must match TurnResult structure from PRD Section 8.6
3. Must save utterances (user and system) for provenance
4. Must track turn count
5. Phase 2: Hardcoded "deepen" strategy
6. Must end at max_turns
7. Must log all major operations
8. Must record latency

## Verification
```bash
# Run session service tests
pytest tests/unit/test_session_service.py -v

# Verify imports
python3 -c "from src.services.session_service import SessionService, TurnResult; print('Session service imported')"
```

## Success Criteria
- [ ] `SessionService` class orchestrates full pipeline
- [ ] `process_turn()` extracts, updates graph, generates question
- [ ] `TurnResult` dataclass matches PRD Section 8.6
- [ ] `start_session()` generates opening question
- [ ] Utterances saved for both user and system
- [ ] Turn count tracked and updated
- [ ] Strategy selection (hardcoded "deepen" for Phase 2)
- [ ] Session ends at max_turns
- [ ] Latency recorded
- [ ] All tests pass with mocked services
