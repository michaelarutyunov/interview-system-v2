# Spec 6.1: Export Service

## Objective
Create the export service for converting session data to various formats.

## Context
- Reference: PRD Section 8.2 (Monitoring & Export), v1 `src/ui/utils/exporters.py`
- Supports JSON, Markdown, and CSV export formats
- Collects all session data including turns, graph, and metadata
- Used for reporting and analysis

## Input Files
- v1: `/home/mikhailarutyunov/projects/graph-enabled-ai-interviewer/src/ui/utils/exporters.py`
- Phase 2: `src/persistence/repositories/session_repo.py` - Session data access
- Phase 2: `src/persistence/repositories/graph_repo.py` - Graph data access

## Output Files

### src/services/export_service.py
```python
"""
Export service for converting session data to various formats.

Supports export to:
- JSON: Full session data with all metadata
- Markdown: Human-readable interview summary
- CSV: Spreadsheet-compatible format for analysis
"""

import json
import csv
from io import StringIO
from typing import Any, Dict, List
from datetime import datetime

import structlog

from src.domain.models.knowledge_graph import KGNode, KGEdge
from src.domain.models.utterance import Utterance


log = structlog.get_logger(__name__)


class ExportService:
    """
    Service for exporting session data to various formats.
    
    Usage:
        service = ExportService()
        json_str = await service.export_session(session_id, "json")
        md_str = await service.export_session(session_id, "markdown")
    """
    
    def __init__(
        self,
        session_repo=None,
        graph_repo=None,
    ):
        """
        Initialize export service.
        
        Args:
            session_repo: Optional session repository (injected for testing)
            graph_repo: Optional graph repository (injected for testing)
        """
        # Lazy import to avoid circular dependencies
        from src.persistence.repositories.session_repo import SessionRepository
        from src.persistence.repositories.graph_repo import GraphRepository
        
        self.session_repo = session_repo or SessionRepository()
        self.graph_repo = graph_repo or GraphRepository()
    
    async def export_session(
        self,
        session_id: str,
        format: str = "json",
    ) -> str:
        """
        Export session data to specified format.
        
        Args:
            session_id: Session ID to export
            format: One of "json", "markdown", "csv"
        
        Returns:
            Exported data as string
        
        Raises:
            ValueError: If format is not supported
            SessionNotFoundError: If session doesn't exist
        """
        log = log.bind(session_id=session_id, format=format)
        log.info("export_session_started")
        
        # Gather all session data
        session_data = await self._collect_session_data(session_id)
        
        # Export to requested format
        if format.lower() in ("json",):
            result = self._export_json(session_data)
        elif format.lower() in ("markdown", "md"):
            result = self._export_markdown(session_data)
        elif format.lower() == "csv":
            result = self._export_csv(session_data)
        else:
            raise ValueError(f"Unsupported export format: {format}")
        
        log.info(
            "export_session_complete",
            format=format,
            output_length=len(result),
        )
        
        return result
    
    async def _collect_session_data(self, session_id: str) -> Dict[str, Any]:
        """
        Collect all session data for export.
        
        Args:
            session_id: Session ID
        
        Returns:
            Dict with all session data
        """
        # Get session metadata
        session = await self.session_repo.get(session_id)
        if not session:
            from src.core.exceptions import SessionNotFoundError
            raise SessionNotFoundError(f"Session {session_id} not found")
        
        # Get utterances
        utterances = await self.session_repo.get_utterances(session_id)
        
        # Get graph data
        nodes = await self.graph_repo.get_nodes(session_id)
        edges = await self.graph_repo.get_edges(session_id)
        
        # Get scoring history
        scoring_history = await self.session_repo.get_scoring_history(session_id)
        
        return {
            "metadata": {
                "session_id": session.id,
                "concept_id": session.concept_id,
                "methodology": session.methodology,
                "status": session.status,
                "created_at": session.created_at.isoformat() if session.created_at else None,
                "completed_at": session.completed_at.isoformat() if session.completed_at else None,
                "config": session.config,
                "exported_at": datetime.utcnow().isoformat(),
            },
            "utterances": [
                {
                    "id": u.id,
                    "turn_number": u.turn_number,
                    "speaker": u.speaker,
                    "text": u.text,
                    "created_at": u.created_at.isoformat() if u.created_at else None,
                }
                for u in utterances
            ],
            "graph": {
                "nodes": [
                    {
                        "id": n.id,
                        "label": n.label,
                        "node_type": n.node_type,
                        "confidence": n.confidence,
                        "properties": n.properties,
                        "source_utterance_ids": n.source_utterance_ids,
                        "recorded_at": n.recorded_at.isoformat() if n.recorded_at else None,
                    }
                    for n in nodes
                ],
                "edges": [
                    {
                        "id": e.id,
                        "source_node_id": e.source_node_id,
                        "target_node_id": e.target_node_id,
                        "edge_type": e.edge_type,
                        "confidence": e.confidence,
                        "properties": e.properties,
                        "source_utterance_ids": e.source_utterance_ids,
                        "recorded_at": e.recorded_at.isoformat() if e.recorded_at else None,
                    }
                    for e in edges
                ],
            },
            "scoring_history": scoring_history,
        }
    
    def _export_json(self, data: Dict[str, Any]) -> str:
        """Export to JSON format."""
        return json.dumps(data, indent=2, default=str)
    
    def _export_markdown(self, data: Dict[str, Any]) -> str:
        """Export to human-readable Markdown format."""
        lines = []
        
        # Header
        meta = data["metadata"]
        lines.append("# Interview Session Export")
        lines.append("")
        lines.append(f"**Session ID:** `{meta['session_id']}`")
        lines.append(f"**Concept:** {meta['concept_id']}")
        lines.append(f"**Methodology:** {meta['methodology']}")
        lines.append(f"**Status:** {meta['status']}")
        lines.append(f"**Created:** {meta.get('created_at', 'N/A')}")
        if meta.get('completed_at'):
            lines.append(f"**Completed:** {meta['completed_at']}")
        lines.append("")
        
        # Statistics
        utterances = data["utterances"]
        nodes = data["graph"]["nodes"]
        edges = data["graph"]["edges"]
        
        lines.append("## Statistics")
        lines.append("")
        lines.append(f"- **Turns:** {len(utterances)}")
        lines.append(f"- **Concepts Extracted:** {len(nodes)}")
        lines.append(f"- **Relationships:** {len(edges)}")
        lines.append("")
        
        # Conversation
        lines.append("## Conversation")
        lines.append("")
        for utt in utterances:
            speaker = utt["speaker"]
            text = utt["text"]
            emoji = "ðŸ‘¤" if speaker == "user" else "ðŸ¤–"
            lines.append(f"### {emoji} {speaker.title()} (Turn {utt['turn_number']})")
            lines.append("")
            lines.append(text)
            lines.append("")
        
        # Knowledge Graph
        lines.append("## Knowledge Graph")
        lines.append("")
        
        # Group nodes by type
        nodes_by_type: Dict[str, List[Dict]] = {}
        for node in nodes:
            node_type = node["node_type"]
            if node_type not in nodes_by_type:
                nodes_by_type[node_type] = []
            nodes_by_type[node_type].append(node)
        
        for node_type, type_nodes in sorted(nodes_by_type.items()):
            lines.append(f"### {node_type.replace('_', ' ').title()} ({len(type_nodes)})")
            lines.append("")
            for node in type_nodes:
                label = node["label"]
                confidence = node["confidence"]
                lines.append(f"- **{label}** (confidence: {confidence:.2f})")
            lines.append("")
        
        # Relationships
        if edges:
            lines.append("### Relationships")
            lines.append("")
            
            # Build node label lookup
            node_labels = {n["id"]: n["label"] for n in nodes}
            
            for edge in edges:
                source_label = node_labels.get(edge["source_node_id"], edge["source_node_id"])
                target_label = node_labels.get(edge["target_node_id"], edge["target_node_id"])
                edge_type = edge["edge_type"]
                confidence = edge["confidence"]
                
                lines.append(f"- {source_label} â†’ **{edge_type}** â†’ {target_label} (confidence: {confidence:.2f})")
            lines.append("")
        
        # Footer
        lines.append("---")
        lines.append(f"*Exported on {meta['exported_at']}*")
        lines.append("")
        
        return "\n".join(lines)
    
    def _export_csv(self, data: Dict[str, Any]) -> str:
        """Export to CSV format with multiple sections."""
        output = StringIO()
        
        # Nodes section
        nodes = data["graph"]["nodes"]
        output.write("## NODES\n")
        if nodes:
            writer = csv.DictWriter(
                output,
                fieldnames=["id", "label", "node_type", "confidence", "source_utterance_ids"]
            )
            writer.writeheader()
            for node in nodes:
                writer.writerow({
                    "id": node["id"],
                    "label": node["label"],
                    "node_type": node["node_type"],
                    "confidence": node["confidence"],
                    "source_utterance_ids": json.dumps(node["source_utterance_ids"]),
                })
        output.write("\n\n")
        
        # Edges section
        edges = data["graph"]["edges"]
        output.write("## EDGES\n")
        if edges:
            writer = csv.DictWriter(
                output,
                fieldnames=["id", "source_node_id", "target_node_id", "edge_type", "confidence"]
            )
            writer.writeheader()
            for edge in edges:
                writer.writerow({
                    "id": edge["id"],
                    "source_node_id": edge["source_node_id"],
                    "target_node_id": edge["target_node_id"],
                    "edge_type": edge["edge_type"],
                    "confidence": edge["confidence"],
                })
        output.write("\n\n")
        
        # Utterances section
        utterances = data["utterances"]
        output.write("## UTTERANCES\n")
        if utterances:
            writer = csv.DictWriter(
                output,
                fieldnames=["id", "turn_number", "speaker", "text", "created_at"]
            )
            writer.writeheader()
            for utt in utterances:
                writer.writerow({
                    "id": utt["id"],
                    "turn_number": utt["turn_number"],
                    "speaker": utt["speaker"],
                    "text": utt["text"],
                    "created_at": utt.get("created_at", ""),
                })
        
        return output.getvalue()
```

### tests/unit/test_export_service.py
```python
"""Tests for export service."""

import pytest
from unittest.mock import AsyncMock, MagicMock

from src.services.export_service import ExportService
from src.domain.models.knowledge_graph import KGNode, KGEdge


class TestExportService:
    """Tests for ExportService."""
    
    @pytest.mark.asyncio
    async def test_export_json_format(self):
        """Export to JSON produces valid JSON."""
        # Mock repositories
        session_repo = AsyncMock()
        graph_repo = AsyncMock()
        
        # Setup mock session
        mock_session = MagicMock()
        mock_session.id = "test-session"
        mock_session.concept_id = "test_concept"
        mock_session.methodology = "means_end_chain"
        mock_session.status = "completed"
        mock_session.created_at = MagicMock()
        mock_session.created_at.isoformat.return_value = "2025-01-21T00:00:00"
        mock_session.completed_at = None
        mock_session.config = {}
        
        session_repo.get.return_value = mock_session
        session_repo.get_utterances.return_value = []
        session_repo.get_scoring_history.return_value = []
        
        # Setup mock graph
        graph_repo.get_nodes.return_value = [
            KGNode(
                id="n1",
                session_id="test-session",
                label="creamy texture",
                node_type="attribute",
                confidence=0.9,
                properties={},
                source_utterance_ids=["u1"],
            )
        ]
        graph_repo.get_edges.return_value = []
        
        service = ExportService(session_repo, graph_repo)
        result = await service.export_session("test-session", "json")
        
        assert result is not None
        # Verify valid JSON
        import json
        data = json.loads(result)
        assert data["metadata"]["session_id"] == "test-session"
        assert len(data["graph"]["nodes"]) == 1
    
    @pytest.mark.asyncio
    async def test_export_markdown_format(self):
        """Export to Markdown produces readable output."""
        session_repo = AsyncMock()
        graph_repo = AsyncMock()
        
        mock_session = MagicMock()
        mock_session.id = "test-session"
        mock_session.concept_id = "oat_milk_v1"
        mock_session.methodology = "means_end_chain"
        mock_session.status = "active"
        mock_session.created_at = MagicMock()
        mock_session.created_at.isoformat.return_value = "2025-01-21T00:00:00"
        mock_session.completed_at = None
        mock_session.config = {}
        
        session_repo.get.return_value = mock_session
        session_repo.get_utterances.return_value = [
            MagicMock(
                id="u1",
                turn_number=1,
                speaker="interviewer",
                text="What comes to mind?",
                created_at=None,
            )
        ]
        session_repo.get_scoring_history.return_value = []
        
        graph_repo.get_nodes.return_value = []
        graph_repo.get_edges.return_value = []
        
        service = ExportService(session_repo, graph_repo)
        result = await service.export_session("test-session", "markdown")
        
        assert "# Interview Session Export" in result
        assert "test-session" in result
        assert "What comes to mind?" in result
    
    @pytest.mark.asyncio
    async def test_export_csv_format(self):
        """Export to CSV produces structured sections."""
        session_repo = AsyncMock()
        graph_repo = AsyncMock()
        
        mock_session = MagicMock()
        mock_session.id = "test-session"
        mock_session.concept_id = "test_concept"
        mock_session.methodology = "means_end_chain"
        mock_session.status = "active"
        mock_session.created_at = MagicMock()
        mock_session.created_at.isoformat.return_value = "2025-01-21T00:00:00"
        mock_session.completed_at = None
        mock_session.config = {}
        
        session_repo.get.return_value = mock_session
        session_repo.get_utterances.return_value = []
        session_repo.get_scoring_history.return_value = []
        
        node = KGNode(
            id="n1",
            session_id="test-session",
            label="test",
            node_type="attribute",
            confidence=0.8,
            properties={},
            source_utterance_ids=[],
        )
        graph_repo.get_nodes.return_value = [node]
        graph_repo.get_edges.return_value = []
        
        service = ExportService(session_repo, graph_repo)
        result = await service.export_session("test-session", "csv")
        
        assert "## NODES" in result
        assert "test" in result
        assert "attribute" in result
    
    @pytest.mark.asyncio
    async def test_unsupported_format_raises(self):
        """Unsupported format raises ValueError."""
        service = ExportService()
        
        with pytest.raises(ValueError, match="Unsupported export format"):
            await service.export_session("test-session", "xml")
```

## Requirements
1. Support JSON, Markdown, and CSV export formats
2. Collect all session data (metadata, utterances, graph, scoring)
3. Format-specific output with proper structure
4. Handle missing data gracefully
5. Proper error handling for missing sessions

## Verification
```bash
# Run tests
pytest tests/unit/test_export_service.py -v

# Verify imports
python3 -c "from src.services.export_service import ExportService; print('OK')"

# Test export formats
python3 -c "
from src.services.export_service import ExportService
service = ExportService()
# Test would require mock repositories
print('Export service initialized')
"
```

## Success Criteria
- [ ] `src/services/export_service.py` created with ExportService class
- [ ] `export_session()` method supports json, markdown, csv formats
- [ ] `_collect_session_data()` gathers all session data
- [ ] `_export_json()` produces valid JSON
- [ ] `_export_markdown()` produces readable markdown
- [ ] `_export_csv()` produces structured sections
- [ ] All tests pass
