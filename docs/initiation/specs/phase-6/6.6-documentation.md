# Spec 6.6: Documentation

## Objective
Create comprehensive project documentation.

## Context
- README.md for project overview
- API documentation via FastAPI OpenAPI
- Developer documentation for contributors
- User documentation for running the system

## Input Files
- IMPLEMENTATION_PLAN.md - Technical overview
- PRD.md - Product requirements
- ENGINEERING_GUIDE.md - Engineering standards

## Output Files

### README.md
```markdown
# Adaptive Interview System v2

An AI-powered qualitative research interview system that conducts adaptive interviews, builds knowledge graphs of consumer mental models in real-time, and achieves systematic coverage of stimulus concepts.

## Features

- **Adaptive Questioning**: AI-generated follow-up questions that respond to what respondents actually say
- **Knowledge Graphs**: Real-time construction of respondent mental models (Means-End Chain methodology)
- **Coverage Tracking**: Systematic exploration of stimulus concept elements
- **Synthetic Respondent**: Automated testing capability with configurable personas
- **Demo UI**: Visual interface with chat, graph visualization, and metrics
- **Export**: Export interviews to JSON, Markdown, or CSV

## Quick Start

### Prerequisites

- Python 3.11+
- Anthropic API key ([Get one here](https://console.anthropic.com/))

### Installation

```bash
# Clone the repository
git clone https://github.com/your-org/interview-system-v2.git
cd interview-system-v2

# Install dependencies (using uv)
uv pip install -e .

# Or using pip
pip install -e .
```

### Configuration

```bash
# Copy environment template
cp .env.example .env

# Edit .env and add your Anthropic API key
echo "ANTHROPIC_API_KEY=your-key-here" >> .env
```

### Running the System

```bash
# Start the FastAPI backend
uvicorn src.main:app --reload

# In another terminal, start the demo UI
streamlit run ui/streamlit_app.py
```

- API: http://localhost:8000
- API Docs: http://localhost:8000/docs
- Demo UI: http://localhost:8501

### Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test suite
pytest tests/unit/
pytest tests/integration/
```

## Project Structure

```
interview-system-v2/
├── src/
│   ├── api/              # FastAPI routes and schemas
│   ├── core/             # Config, logging, exceptions
│   ├── domain/           # Domain models
│   ├── llm/              # LLM client and prompts
│   ├── persistence/      # Database layer
│   ├── services/         # Business logic
│   └── utils/            # Utilities
├── config/               # Configuration files
├── tests/                # Tests
├── specs/                # Implementation specs
├── scripts/              # Utility scripts
└── docs/                 # Documentation
```

## API Documentation

Once running, visit http://localhost:8000/docs for interactive API documentation.

### Key Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/sessions` | POST | Create new interview session |
| `/sessions/{id}` | GET | Get session details |
| `/sessions/{id}/turns` | POST | Submit interview turn |
| `/sessions/{id}/export` | GET | Export session data |
| `/synthetic/respond` | POST | Generate synthetic response |
| `/concepts` | GET | List available concepts |

## Usage

### Creating an Interview

```python
import httpx

async with httpx.AsyncClient() as client:
    # Create session
    response = await client.post(
        "http://localhost:8000/sessions",
        json={"concept_id": "oat_milk_v1"}
    )
    session = response.json()
    
    # Submit turns
    response = await client.post(
        f"http://localhost:8000/sessions/{session['id']}/turns",
        json={"user_input": "I like the creamy texture"}
    )
    result = response.json()
    print(result["next_question"])
```

### Using the Synthetic Respondent

```bash
# Run automated interview test
python scripts/run_synthetic_interview.py --persona health_conscious
```

## Development

### Running Phase by Phase

The project is organized into implementation phases. See `specs/` for detailed task specifications.

- Phase 1: Foundation (API, database, sessions)
- Phase 2: Core Pipeline (extraction, graph, questions)
- Phase 3: Scoring & Strategy (adaptive behavior)
- Phase 4: Synthetic Respondent (automated testing)
- Phase 5: Demo UI (visual interface)
- Phase 6: Export & Polish (production-ready)

### Adding a New Persona

Edit `src/llm/prompts/synthetic.py` and add to the `PERSONAS` dict.

### Adding a New Concept

Create a YAML file in `config/concepts/` following the format in `config/concepts/oat_milk.yaml`.

## License

MIT

## Acknowledgments

Built with:
- FastAPI for the API
- Streamlit for the demo UI
- Anthropic Claude for LLM capabilities
- SQLite for data persistence
```

### docs/API.md
```markdown
# API Documentation

## Base URL

```
http://localhost:8000
```

## Authentication

Currently no authentication (single-user system).

## Response Format

Success responses return data. Error responses follow this format:

```json
{
  "error": {
    "type": "SessionNotFoundError",
    "message": "Session not found",
    "details": {}
  }
}
```

## Sessions

### Create Session

```http
POST /sessions
Content-Type: application/json

{
  "concept_id": "oat_milk_v1",
  "max_turns": 20,
  "target_coverage": 0.8
}
```

### Submit Turn

```http
POST /sessions/{id}/turns
Content-Type: application/json

{
  "user_input": "The response text"
}
```

### Get Session Status

```http
GET /sessions/{id}/status
```

### Export Session

```http
GET /sessions/{id}/export?format=json
```

Formats: `json`, `markdown`, `csv`

## Synthetic Respondent

### Generate Response

```http
POST /synthetic/respond
Content-Type: application/json

{
  "question": "Why is creamy texture important?",
  "session_id": "session-123",
  "persona": "health_conscious"
}
```

## Concepts

### List Concepts

```http
GET /concepts
```

### Get Concept Details

```http
GET /concepts/{id}
```
```

### docs/DEVELOPMENT.md
```markdown
# Development Guide

## Setting Up Development Environment

```bash
# Fork and clone repository
git clone https://github.com/your-username/interview-system-v2.git
cd interview-system-v2

# Create virtual environment
python -m venv .venv
source .venv/bin/activate

# Install dependencies
uv pip install -e ".[dev]"

# Run pre-commit hooks (if configured)
pre-commit install
```

## Running Tests

```bash
# Unit tests
pytest tests/unit/ -v

# Integration tests (require running API)
pytest tests/integration/ -v

# With coverage
pytest --cov=src --cov-report=html
open htmlcov/index.html
```

## Code Style

- Format with Black: `black src/`
- Sort imports: `isort src/`
- Type hints required for public functions

## Adding Features

1. Create a spec in `specs/` for the phase/feature
2. Implement following the spec
3. Add tests
4. Update documentation
5. Submit PR

## Debugging

```bash
# Enable debug logging
export DEBUG=true

# Run with verbose output
uvicorn src.main:app --log-level debug
```
```

## Requirements
1. README.md with overview and quick start
2. API documentation
3. Development guide
4. Installation instructions
5. Usage examples
6. Project structure explanation

## Verification
```bash
# Verify README exists and has required sections
grep -q "## Features" README.md
grep -q "## Quick Start" README.md
grep -q "## Installation" README.md
grep -q "## Usage" README.md

# Check docs exist
ls -la docs/API.md docs/DEVELOPMENT.md

# Check links in markdown
if command -v markdown-link-check >/dev/null 2>&1; then
    markdown-link-check *.md docs/
fi
```

## Success Criteria
- [ ] README.md with overview and quick start
- [ ] Installation instructions
- [ ] Usage examples
- [ ] API documentation
- [ ] Development guide
- [ ] Project structure explanation
- [ ] All required sections present
