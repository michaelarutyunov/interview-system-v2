# Spec 4.4: Test Script

## Objective
Create a test script for running automated synthetic interviews end-to-end.

## Context
- Reference: PRD Section 6.2 (Flow 2: Automated Testing)
- Standalone script that runs a complete interview with synthetic respondent
- Validates coverage, graph coherence, and session completion
- Useful for regression testing and development iteration

## Input Files
- Phase 2: `src/api/routes/sessions.py` - Session endpoints
- Phase 4.3: `src/api/routes/synthetic.py` - Synthetic endpoint
- Phase 2: `config/concepts/example_oat_milk.yaml` - Example concept config

## Output Files

### scripts/run_synthetic_interview.py
```python
#!/usr/bin/env python3
"""
Automated synthetic interview test script.

Runs a complete interview using the synthetic respondent:
1. Creates a session with concept configuration
2. Iterates through turns (question → synthetic response)
3. Validates coverage, graph state, and completion
4. Reports results

Usage:
    python scripts/run_synthetic_interview.py --persona health_conscious
    python scripts/run_synthetic_interview.py --max-turns 10 --coverage 0.7
    python scripts/run_synthetic_interview.py --output results.json
"""

import argparse
import asyncio
import json
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, Any

import httpx


# Configuration
DEFAULT_API_URL = "http://localhost:8000"
DEFAULT_CONCEPT_ID = "oat_milk_v1"
DEFAULT_PERSONA = "health_conscious"
DEFAULT_MAX_TURNS = 20
DEFAULT_TARGET_COVERAGE = 0.8


async def create_session(
    client: httpx.AsyncClient,
    api_url: str,
    concept_id: str = DEFAULT_CONCEPT_ID,
) -> Dict[str, Any]:
    """
    Create a new interview session.
    
    Args:
        client: HTTP client
        api_url: Base API URL
        concept_id: Concept configuration ID
    
    Returns:
        Session data dict
    """
    response = await client.post(
        f"{api_url}/sessions",
        json={
            "concept_id": concept_id,
            "max_turns": DEFAULT_MAX_TURNS,
            "target_coverage": DEFAULT_TARGET_COVERAGE,
        },
    )
    response.raise_for_status()
    return response.json()


async def get_synthetic_response(
    client: httpx.AsyncClient,
    api_url: str,
    question: str,
    session_id: str,
    persona: str,
    interview_context: Dict[str, Any],
) -> Dict[str, Any]:
    """
    Get synthetic response to a question.
    
    Args:
        client: HTTP client
        api_url: Base API URL
        question: Interview question
        session_id: Session ID
        persona: Persona to use
        interview_context: Interview context dict
    
    Returns:
        Synthetic response dict
    """
    response = await client.post(
        f"{api_url}/synthetic/respond",
        json={
            "question": question,
            "session_id": session_id,
            "persona": persona,
            "interview_context": interview_context,
        },
    )
    response.raise_for_status()
    return response.json()


async def submit_turn(
    client: httpx.AsyncClient,
    api_url: str,
    session_id: str,
    user_input: str,
) -> Dict[str, Any]:
    """
    Submit a turn to the session.
    
    Args:
        client: HTTP client
        api_url: Base API URL
        session_id: Session ID
        user_input: Respondent's answer
    
    Returns:
        Turn result dict
    """
    response = await client.post(
        f"{api_url}/sessions/{session_id}/turns",
        json={"user_input": user_input},
    )
    response.raise_for_status()
    return response.json()


async def get_session_status(
    client: httpx.AsyncClient,
    api_url: str,
    session_id: str,
) -> Dict[str, Any]:
    """
    Get current session status.
    
    Args:
        client: HTTP client
        api_url: Base API URL
        session_id: Session ID
    
    Returns:
        Session status dict
    """
    response = await client.get(
        f"{api_url}/sessions/{session_id}/status",
    )
    response.raise_for_status()
    return response.json()


async def run_interview(
    api_url: str,
    persona: str,
    concept_id: str,
    max_turns: int,
    verbose: bool = False,
) -> Dict[str, Any]:
    """
    Run a complete synthetic interview.
    
    Args:
        api_url: Base API URL
        persona: Persona to use
        concept_id: Concept configuration ID
        max_turns: Maximum turns to run
        verbose: Print detailed output
    
    Returns:
        Interview results dict
    """
    results = {
        "persona": persona,
        "concept_id": concept_id,
        "start_time": datetime.utcnow().isoformat(),
        "turns": [],
        "final_status": None,
        "success": False,
        "error": None,
    }
    
    try:
        async with httpx.AsyncClient(timeout=60.0) as client:
            # Create session
            if verbose:
                print(f"Creating session for concept: {concept_id}")
            
            session = await create_session(client, api_url, concept_id)
            session_id = session["id"]
            
            if verbose:
                print(f"Session created: {session_id}")
                print(f"Opening question: {session.get('opening_question', 'N/A')}")
            
            results["session_id"] = session_id
            results["opening_question"] = session.get("opening_question")
            
            # Run turns
            for turn_num in range(1, max_turns + 1):
                # Get current status
                status = await get_session_status(client, api_url, session_id)
                
                question = status.get("next_question")
                if not question:
                    if verbose:
                        print("No more questions - interview complete")
                    break
                
                coverage = status.get("coverage", 0.0)
                should_continue = status.get("should_continue", True)
                
                if verbose:
                    print(f"\n--- Turn {turn_num} ---")
                    print(f"Coverage: {coverage*100:.1f}%")
                    print(f"Question: {question}")
                
                # Get synthetic response
                interview_context = {
                    "product_name": "Oat Milk",  # From concept config
                    "turn_number": turn_num,
                    "coverage_achieved": coverage,
                }
                
                synthetic_result = await get_synthetic_response(
                    client, api_url, question, session_id, persona, interview_context
                )
                
                synthetic_response = synthetic_result["response"]
                
                if verbose:
                    print(f"Response: {synthetic_response}")
                    print(f"Latency: {synthetic_result['latency_ms']:.0f}ms")
                
                # Submit turn
                turn_result = await submit_turn(
                    client, api_url, session_id, synthetic_response
                )
                
                turn_data = {
                    "turn_number": turn_num,
                    "question": question,
                    "response": synthetic_response,
                    "extracted_concepts": turn_result.get("extracted", {}).get("concepts", []),
                    "strategy": turn_result.get("strategy_selected"),
                    "coverage": turn_result.get("scoring", {}).get("coverage", 0.0),
                    "should_continue": turn_result.get("should_continue", True),
                }
                
                results["turns"].append(turn_data)
                
                if verbose:
                    print(f"Strategy: {turn_data['strategy']}")
                    print(f"Concepts extracted: {len(turn_data['extracted_concepts'])}")
                
                # Check if should continue
                if not should_continue:
                    if verbose:
                        print("Interview naturally complete")
                    break
            
            # Get final status
            final_status = await get_session_status(client, api_url, session_id)
            results["final_status"] = final_status
            results["end_time"] = datetime.utcnow().isoformat()
            results["success"] = True
            
            if verbose:
                print(f"\n=== Interview Complete ===")
                print(f"Total turns: {len(results['turns'])}")
                print(f"Final coverage: {final_status.get('coverage', 0)*100:.1f}%")
                print(f"Status: {final_status.get('status', 'unknown')}")
    
    except Exception as e:
        results["error"] = str(e)
        results["end_time"] = datetime.utcnow().isoformat()
    
    return results


def validate_results(results: Dict[str, Any]) -> bool:
    """
    Validate interview results against success criteria.
    
    Args:
        results: Interview results from run_interview
    
    Returns:
        True if all validation checks pass
    """
    print("\n=== Validation ===")
    
    if not results["success"]:
        print(f"❌ Interview failed: {results['error']}")
        return False
    
    final_status = results.get("final_status", {})
    coverage = final_status.get("coverage", 0.0)
    turn_count = len(results.get("turns", []))
    
    checks_passed = 0
    checks_total = 0
    
    # Check 1: Coverage ≥ 80%
    checks_total += 1
    if coverage >= 0.8:
        print(f"✅ Coverage: {coverage*100:.1f}% ≥ 80%")
        checks_passed += 1
    else:
        print(f"❌ Coverage: {coverage*100:.1f}% < 80%")
    
    # Check 2: At least 5 turns
    checks_total += 1
    if turn_count >= 5:
        print(f"✅ Turns: {turn_count} ≥ 5")
        checks_passed += 1
    else:
        print(f"❌ Turns: {turn_count} < 5")
    
    # Check 3: No errors in turns
    checks_total += 1
    turn_errors = [t for t in results.get("turns", []) if t.get("error")]
    if not turn_errors:
        print(f"✅ No turn errors")
        checks_passed += 1
    else:
        print(f"❌ {len(turn_errors)} turn errors")
    
    # Check 4: At least 10 concepts extracted
    checks_total += 1
    total_concepts = sum(
        len(t.get("extracted_concepts", []))
        for t in results.get("turns", [])
    )
    if total_concepts >= 10:
        print(f"✅ Concepts extracted: {total_concepts} ≥ 10")
        checks_passed += 1
    else:
        print(f"❌ Concepts extracted: {total_concepts} < 10")
    
    # Check 5: Session status is completed or coverage_met
    checks_total += 1
    status = final_status.get("status", "")
    if status in ["completed", "coverage_met", "active"]:
        print(f"✅ Session status: {status}")
        checks_passed += 1
    else:
        print(f"⚠️  Session status: {status} (unexpected)")
    
    print(f"\nPassed: {checks_passed}/{checks_total} checks")
    return checks_passed == checks_total


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="Run automated synthetic interview test"
    )
    parser.add_argument(
        "--api-url",
        default=DEFAULT_API_URL,
        help=f"API base URL (default: {DEFAULT_API_URL})",
    )
    parser.add_argument(
        "--persona",
        default=DEFAULT_PERSONA,
        choices=[
            "health_conscious",
            "price_sensitive",
            "convenience_seeker",
            "quality_focused",
            "sustainability_minded",
        ],
        help="Persona to use (default: health_conscious)",
    )
    parser.add_argument(
        "--concept-id",
        default=DEFAULT_CONCEPT_ID,
        help="Concept configuration ID (default: oat_milk_v1)",
    )
    parser.add_argument(
        "--max-turns",
        type=int,
        default=DEFAULT_MAX_TURNS,
        help=f"Maximum turns to run (default: {DEFAULT_MAX_TURNS})",
    )
    parser.add_argument(
        "--output", "-o",
        type=Path,
        help="Output JSON file for results",
    )
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="Print detailed output",
    )
    
    args = parser.parse_args()
    
    print(f"Starting synthetic interview test...")
    print(f"  API URL: {args.api_url}")
    print(f"  Persona: {args.persona}")
    print(f"  Concept: {args.concept_id}")
    print(f"  Max turns: {args.max_turns}")
    
    results = asyncio.run(run_interview(
        api_url=args.api_url,
        persona=args.persona,
        concept_id=args.concept_id,
        max_turns=args.max_turns,
        verbose=args.verbose,
    ))
    
    # Output results
    if args.output:
        args.output.write_text(json.dumps(results, indent=2))
        print(f"\nResults saved to: {args.output}")
    
    # Validate
    success = validate_results(results)
    
    # Exit with appropriate code
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
```

### scripts/README.md (create/update)
```markdown
# Interview System Scripts

This directory contains utility scripts for testing and development.

## run_synthetic_interview.py

Automated test script that runs a complete interview using the synthetic respondent.

### Usage

Basic usage:
```bash
python scripts/run_synthetic_interview.py
```

With custom persona:
```bash
python scripts/run_synthetic_interview.py --persona price_sensitive
```

With output file:
```bash
python scripts/run_synthetic_interview.py --output results.json
```

Verbose mode (see detailed output):
```bash
python scripts/run_synthetic_interview.py --verbose
```

Custom API URL:
```bash
python scripts/run_synthetic_interview.py --api-url http://localhost:8001
```

### Options

| Option | Default | Description |
|--------|---------|-------------|
| `--api-url` | `http://localhost:8000` | API base URL |
| `--persona` | `health_conscious` | Persona to use |
| `--concept-id` | `oat_milk_v1` | Concept configuration ID |
| `--max-turns` | `20` | Maximum turns to run |
| `--output`, `-o` | None | Save results to JSON file |
| `--verbose`, `-v` | False | Print detailed output |

### Personas

- `health_conscious` - Health-Conscious Millennial
- `price_sensitive` - Budget-Conscious Shopper
- `convenience_seeker` - Busy Professional
- `quality_focused` - Quality Enthusiast
- `sustainability_minded` - Environmentally Conscious Consumer

### Validation Checks

The script validates:
1. Coverage ≥ 80%
2. At least 5 turns completed
3. No errors in turns
4. At least 10 concepts extracted
5. Valid session status

Exit code 0 if all checks pass, 1 otherwise.
```

## Requirements
1. Script must be executable (`chmod +x`)
2. Use asyncio for async HTTP calls
3. Accept command-line arguments for persona, max_turns, api_url
4. Save results to optional JSON output file
5. Validate results against success criteria
6. Return appropriate exit codes (0=success, 1=failure)

## Verification
```bash
# Make executable
chmod +x scripts/run_synthetic_interview.py

# Run with default settings
python scripts/run_synthetic_interview.py

# Run with verbose output
python scripts/run_synthetic_interview.py --verbose

# Run with specific persona
python scripts/run_synthetic_interview.py --persona price_sensitive --output results.json

# Check results
cat results.json | jq '.success, .final_status.coverage'
```

## Success Criteria
- [ ] `scripts/run_synthetic_interview.py` created and executable
- [ ] `create_session()` - creates interview session
- [ ] `get_synthetic_response()` - calls synthetic endpoint
- [ ] `submit_turn()` - submits turn to session
- [ ] `get_session_status()` - gets current status
- [ ] `run_interview()` - runs complete interview loop
- [ ] `validate_results()` - validates against criteria
- [ ] `main()` - CLI with argparse
- [ ] Script executes successfully with API running
