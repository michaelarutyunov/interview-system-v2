# Spec 6.5: Logging Review

## Objective
Ensure consistent structured logging throughout the codebase.

## Context
- Reference: ENGINEERING_GUIDE.md Section 5 (Logging with structlog)
- Structured logging with contextvars
- Log levels for different event types
- Request tracing across async calls

## Input Files
- ENGINEERING_GUIDE.md Section 5
- src/core/logging.py - Logging configuration

## Output Files

### docs/logging_standards.md
```markdown
# Logging Standards

## Configuration

All logging uses `structlog` with context-bound loggers.

```python
from src.core.logging import get_logger

log = get_logger(__name__)
```

## Event Logging Standards

| Event | Level | Required Fields |
|-------|-------|-----------------|
| Request received | INFO | endpoint, method, session_id |
| LLM call start | DEBUG | provider, model, prompt_tokens (estimated) |
| LLM call complete | INFO | provider, model, latency_ms, tokens_used |
| LLM call failed | ERROR | provider, model, error_type, error_message |
| Extraction complete | INFO | session_id, turn_number, concept_count |
| Strategy selected | INFO | session_id, turn_number, strategy, scores |
| Session created | INFO | session_id, methodology, concept_id |
| Session completed | INFO | session_id, turns, coverage, duration_seconds |
| Database query | DEBUG | query, table, rows_affected |
| Error | ERROR | error_type, error_message, context |

## Binding Context

Always bind relevant context to loggers:

```python
log = log.bind(session_id=session_id, turn_number=turn)

log.info("processing_turn", response_length=len(response))

try:
    result = await process(data)
    log.info("processing_complete", result_count=len(result))
except Exception as e:
    log.error("processing_failed", error_type=type(e).__name__, error_message=str(e))
    raise
```

## Level Guidelines

- **DEBUG**: Detailed diagnostics (queries, token counts, timing)
- **INFO**: Normal operations (requests, completions, state changes)
- **WARNING**: Recoverable issues (retries, degraded behavior)
- **ERROR**: Errors that affect operation but don't crash
- **CRITICAL**: System-wide failures

## Do Not Log

- Passwords, API keys, or secrets
- Large payloads (log length, not content)
- PII in production (use user_id instead)
```

### src/core/logging.py (verification)
```python
"""Verify logging configuration exists."""

import structlog
from src.core.config import settings


def configure_logging() -> None:
    """Configure structlog for the application."""
    
    shared_processors = [
        structlog.contextvars.merge_contextvars,
        structlog.processors.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.stdlib.ExtraAdder(),
    ]
    
    if settings.debug:
        processors = shared_processors + [
            structlog.dev.ConsoleRenderer(colors=True)
        ]
    else:
        processors = shared_processors + [
            structlog.processors.dict_tracebacks,
            structlog.processors.JSONRenderer()
        ]
    
    structlog.configure(
        processors=processors,
        wrapper_class=structlog.make_filtering_bound_logger(logging.INFO),
        context_class=dict,
        logger_factory=structlog.PrintLoggerFactory(),
        cache_logger_on_first_use=True,
    )


def get_logger(name: str) -> structlog.BoundLogger:
    """Get a logger instance with the given name."""
    return structlog.get_logger(name)
```

### tests/unit/test_logging.py
```python
"""Tests for logging configuration."""

import logging
import pytest
import structlog

from src.core.logging import configure_logging, get_logger


class TestLoggingConfiguration:
    """Tests for logging setup."""
    
    def test_configure_logging_sets_up_structlog(self):
        """configure_logging() sets up structlog properly."""
        configure_logging()
        
        # Get a logger and verify it works
        logger = structlog.get_logger("test")
        assert logger is not None
    
    def test_get_logger_returns_bound_logger(self):
        """get_logger() returns a BoundLogger."""
        logger = get_logger("test_module")
        
        assert isinstance(logger, structlog.BoundLogger)
    
    def test_logger_can_bind_context(self):
        """Logger can bind context variables."""
        logger = get_logger("test")
        
        bound_logger = logger.bind(session_id="test-123", turn_number=5)
        
        # Should not raise
        bound_logger.info("test_message")
    
    def test_debug_mode_uses_dev_renderer(self):
        """Debug mode uses ConsoleRenderer with colors."""
        from src.core.config import Settings
        from unittest.mock import patch
        
        with patch.object(Settings, "debug", True):
            configure_logging()
            
            # Verify dev renderer is configured
            # (This would check the actual configuration)
    
    def test_production_mode_uses_json_renderer(self):
        """Production mode uses JSONRenderer."""
        from src.core.config import Settings
        from unittest.mock import patch
        
        with patch.object(Settings, "debug", False):
            configure_logging()
            
            # Verify JSON renderer is configured
            # (This would check the actual configuration)
```

### scripts/check_logging.py
```python
#!/usr/bin/env python3
"""
Script to check logging consistency across the codebase.

Scans Python files for:
- Missing log imports
- Direct print() statements (should use logging)
- Inconsistent log levels
"""

import ast
import sys
from pathlib import Path
from typing import List, Dict, Set


class LoggingChecker(ast.NodeVisitor):
    """AST visitor to check logging patterns."""
    
    def __init__(self, filename: str):
        self.filename = filename
        self.issues = []
        self.has_logging_import = False
        self.print_calls = []
    
    def visit_Import(self, node: ast.Import):
        """Check for logging imports."""
        for alias in node.names:
            if "logging" in alias.name or "structlog" in alias.name:
                self.has_logging_import = True
    
    def visit_ImportFrom(self, node: ast.ImportFrom):
        """Check for from imports."""
        if node.module and ("logging" in node.module or "structlog" in node.module):
            self.has_logging_import = True
    
    def visit_Call(self, node: ast.Call):
        """Check for print() calls."""
        if isinstance(node.func, ast.Name) and node.func.id == "print":
            self.print_calls.append(
                f"Line {node.lineno}: print() call (should use logging)"
            )


def check_file(filepath: Path) -> List[str]:
    """Check a single file for logging issues."""
    issues = []
    
    try:
        with open(filepath) as f:
            source = f.read()
        
        tree = ast.parse(source, filename=str(filepath))
        checker = LoggingChecker(str(filepath))
        checker.visit(tree)
        
        if not checker.has_logging_import and "test_" not in filepath.name:
            # Check if file has any async functions or API routes
            # If so, it should probably have logging
            for node in ast.walk(tree):
                if isinstance(node, (ast.AsyncFunctionDef, ast.FunctionDef)):
                    issues.append(f"{filepath}: Missing logging import")
                    break
        
        for print_issue in checker.print_calls:
            issues.append(f"{filepath}: {print_issue}")
    
    except Exception as e:
        issues.append(f"{filepath}: Failed to parse: {e}")
    
    return issues


def main():
    """Run logging checker on all Python files."""
    src_dir = Path("src")
    
    if not src_dir.exists():
        print("Source directory not found")
        return 1
    
    all_issues = []
    
    for py_file in src_dir.rglob("*.py"):
        issues = check_file(py_file)
        all_issues.extend(issues)
    
    if all_issues:
        print("Logging issues found:")
        for issue in all_issues:
            print(f"  ⚠️  {issue}")
        return 1
    else:
        print("✅ No logging issues found")
        return 0


if __name__ == "__main__":
    sys.exit(main())
```

## Requirements
1. Use structlog for all logging
2. Bind context (session_id, turn_number, etc.)
3. Follow event logging standards table
4. No print() statements in production code
5. Appropriate log levels
6. Log all external API calls
7. Log all errors with context

## Verification
```bash
# Run logging tests
pytest tests/unit/test_logging.py -v

# Run logging checker
python scripts/check_logging.py

# Verify logging imports
grep -r "from src.core.logging import get_logger" src/ | wc -l

# Check for print statements (should be minimal)
grep -r "print(" src/ --include="*.py" | grep -v "test_" | wc -l
```

## Success Criteria
- [ ] Logging configuration in place
- [ ] get_logger() used in all services
- [ ] Context binding throughout
- [ ] No print() statements in src/ (except tests)
- [ ] All external calls logged
- [ ] Consistent event fields
- [ ] Tests pass
- [ ] Check script passes
