# Means-End Chain Methodology Configuration
#
# MEC explores chains from attributes → consequences → values
# by asking "why is that important?" to probe deeper.

method:
  name: means_end_chain
  version: "3.0"
  goal: "Explore causal chains from concrete attributes to abstract values"
  opening_bias: "Elicit concrete, experience-based responses. Ask for specific examples and situations."
  description: "Laddering: attributes → consequences → values"

ontology:
  nodes:
    - name: attribute
      level: 1
      terminal: false
      description: "Concrete product feature or characteristic"
      examples:
        - "creamy texture"
        - "plant-based"
        - "sustainable packaging"

    - name: functional_consequence
      level: 2
      terminal: false
      description: "Tangible outcome from using the product"
      examples:
        - "easier to digest"
        - "mixes well with coffee"

    - name: psychosocial_consequence
      level: 3
      terminal: false
      description: "Emotional or social outcome"
      examples:
        - "feel healthier"
        - "gain respect from peers"

    - name: instrumental_value
      level: 4
      terminal: false
      description: "Preferred mode of behavior"
      examples:
        - "being responsible"
        - "taking care of myself"

    - name: terminal_value
      level: 5
      terminal: true
      description: "End-state of existence, core life goal"
      examples:
        - "self-respect"
        - "sense of accomplishment"
        - "family security"

  edges:
    - name: leads_to
      description: "Causal or enabling relationship"
      permitted_connections:
        - [attribute, attribute]
        - [attribute, functional_consequence]
        - [functional_consequence, functional_consequence]
        - [functional_consequence, psychosocial_consequence]
        - [psychosocial_consequence, psychosocial_consequence]
        - [psychosocial_consequence, instrumental_value]
        - [instrumental_value, instrumental_value]
        - [instrumental_value, terminal_value]

    - name: revises
      description: "Contradiction - newer belief supersedes older one"
      permitted_connections:
        - ["*", "*"]

  extraction_guidelines:
    - "For Means-End Chain interviews, extract BOTH explicit AND implicit relationships"
    - "Explicit: Look for causal markers like 'because', 'so', 'that's why', 'leads to'"
    - "Implicit (MEC chains): When multiple concepts are mentioned in the same response, connect them if they form a logical means-end chain"
    - "Contextual: If the interviewer asks 'why does X matter' and the response describes Y, create X→Y relationship"
    - "For Means-End Chain interviews, create edges between concepts that represent the chain of reasoning, even when no explicit connector is used"
    - "attribute → functional_consequence (features → outcomes)"
    - "functional_consequence → psychosocial_consequence (outcomes → feelings)"
    - "psychosocial_consequence → instrumental_value (feelings → goals)"
    - "instrumental_value → terminal_value (goals → life values)"
    - "Target 2-3x more edges than nodes for a well-structured MEC graph"
    - "Prefer creating relationships over leaving concepts disconnected"

  relationship_examples:
    explicit_causal:
      description: "Discourse markers explicitly state the connection"
      example: "I like froth because it makes coffee less bitter"
      extraction: "froth → makes coffee taste less bitter"

    implicit_same_response:
      description: "Multiple concepts in one response form logical consequence chain"
      example: "Froth makes coffee taste less bitter and gives a nice sensation in the mouth"
      extraction: "makes coffee taste less bitter → nice sensation in the mouth"

    implicit_conversational:
      description: "Question establishes antecedent, response provides consequence"
      example: "Interviewer: 'Why does the nice sensation matter?' Respondent: 'It feels like a good start of the day'"
      extraction: "nice sensation in the mouth → good start of the day"

    value_progression:
      description: "Parallel goals forming a chain toward terminal value"
      example: "I can be my best and set a good example to my kids"
      extraction: "be my best → set a good example to my kids"

  extractability_criteria:
    extractable_contains:
      - "Product attributes, features, or characteristics"
      - "Benefits, outcomes, or consequences"
      - "Feelings, emotions, or social implications"
      - "Values or life goals"
      - "Causal relationships between any of the above"
    non_extractable_contains:
      - "Simple yes/no responses"
      - "Acknowledgments ('okay', 'I see')"
      - "Questions back to the interviewer"
      - "Off-topic tangents"
      - "Very short responses with no substance"

  concept_naming_convention: >
    Name each concept according to its level in the means-end chain:
    attributes as concrete product features or characteristics,
    consequences as functional or psychosocial outcomes,
    values as abstract personal values or life goals.
    Use the examples in each node type description as naming models.

signals:
  graph:
    - graph.node_count
    - graph.max_depth
    - graph.avg_depth
    - graph.orphan_count
    - graph.chain_completion
    # Canonical graph signals (Phase 4, experimental)
    - graph.canonical_concept_count
    - graph.canonical_edge_density
    - graph.canonical_exhaustion_score

  llm:
    - llm.response_depth
    - llm.valence
    - llm.certainty
    - llm.specificity
    - llm.engagement
    # Note: llm.global_response_trend is session-scoped and managed separately

  temporal:
    - temporal.strategy_repetition_count
    - temporal.turns_since_strategy_change

  meta:
    - meta.interview_progress
    - meta.interview.phase
    - meta.conversation.saturation
    - meta.canonical.saturation

strategies:
  # Strategy 1: Deepen the chain (laddering)
  - name: deepen
    description: "Explore why something matters to understand deeper motivations and values through progressive 'why' questioning"
    signal_weights:
      # Global signals
      llm.response_depth.low: 0.8
      llm.response_depth.mid: 0.3
      llm.response_depth.moderate: 0.15  # Even moderate answers can benefit from deepening
      graph.max_depth: -0.3
      graph.chain_completion.has_complete.false: 1.0
      # Engagement & valence safety checks — mid-engagement now contributes
      llm.engagement.high: 0.5              # Engaged = safe to deepen (was 0.7)
      llm.engagement.mid: 0.3               # Moderate engagement = still OK to deepen (NEW)
      llm.engagement.low: -0.5              # Disengaged = avoid deepening
      llm.valence.high: 0.4                 # Positive emotion = safe to go deeper
      # Response quality trend — deepen when quality is declining
      llm.global_response_trend.shallowing: 0.4  # Shallow trend → try deepening (NEW)
      # Diversity
      temporal.strategy_repetition_count: -0.3
      # Node-level signals (Phase 3)
      graph.node.exhaustion_score.low: 1.0  # Boost non-exhausted nodes
      graph.node.focus_streak.low: 0.5  # Prefer fresh nodes

  # Strategy 2: Clarify relationships (probing)
  - name: clarify
    description: "Rephrase the question in simpler, clearer words when user shows confusion or lack of understanding"
    signal_weights:
      # LLM-based clarification triggers
      llm.specificity.low: 0.8              # Vague language = needs clarification
      llm.certainty.low: 0.5                # Uncertainty = needs validation
      llm.engagement.mid: 0.3               # Moderate engagement = clarify OK
      # Diversity
      temporal.strategy_repetition_count: -0.3
      temporal.turns_since_strategy_change: -0.3  # Break strategy lock
      # Node-level signals (Phase 3) — reduced to prevent node dominance
      graph.node.is_orphan.true: 0.7  # Boost orphan nodes (was 1.0)
      graph.node.exhaustion_score.low: 0.4  # (was 0.5)
      graph.node.focus_streak.none: 0.3

  # Strategy 3: Explore new areas (elaboration)
  - name: explore
    description: "Find new branches and related concepts by asking 'what else?' to expand breadth"
    signal_weights:
      # Global signals
      llm.certainty.low: 0.4
      temporal.strategy_repetition_count: -0.8  # Strong repetition penalty (was -0.3)
      # Engagement & valence
      llm.engagement.mid: 0.4               # Moderate engagement = breadth OK
      llm.valence.low: 0.3                  # Negative emotion = change topic
      # Response quality awareness — suppress exploration during declining quality
      llm.global_response_trend.shallowing: -0.4  # Don't explore when answers declining
      llm.global_response_trend.fatigued: -0.6    # Strongly suppress during fatigue
      # Node-level signals (Phase 3) — reduced weights to prevent node dominance
      graph.node.focus_streak.none: 0.6  # Fresh nodes (was 1.0)
      graph.node.yield_stagnation.false: 0.5  # Nodes that yield (was 0.8)
      graph.node.exhaustion_score.low: 0.4  # Avoid exhausted nodes (was 0.7)

  # Strategy 4: Reflect and validate (validation)
  - name: reflect
    description: "Summarize what you've heard and invite correction or addition to validate understanding"
    signal_weights:
      # Global signals
      graph.max_depth: 0.7
      meta.interview_progress: 0.5
      llm.response_depth.high: 0.6
      # Uncertainty/hedging triggers (Phase 5)
      llm.certainty.low: 0.7  # Trigger on high uncertainty
      llm.certainty.mid: 0.7  # Trigger on medium uncertainty
      meta.node.opportunity.probe_deeper: 0.6  # Extraction opportunity
      # Engagement trigger
      llm.engagement.low: 0.6               # Low engagement = validate & wrap
      # Diversity (lighter penalty — OK to repeat reflection)
      temporal.strategy_repetition_count: -0.2
      # Node-level signals (Phase 3)
      graph.node.has_outgoing.true: 0.8  # Well-connected nodes
      graph.node.focus_streak.high: 0.5  # Often-focused nodes
      technique.node.strategy_repetition.low: 0.3  # Avoid overusing same strategy
      # Saturation triggers (Phase 6)
      meta.conversation.saturation: 0.5  # High saturation = validate
      meta.canonical.saturation: 0.3     # Supportive metric

  # Strategy 5: Revitalize engagement (elaboration) - Phase 5
  - name: revitalize
    description: "Shift to fresh topics when response trend shows fatigue or repeated shallow answers"
    signal_weights:
      # Fatigue detection triggers (Phase 5)
      llm.global_response_trend.fatigued: 1.0  # Trigger on fatigue
      llm.global_response_trend.shallowing: 0.5  # Prevent fatigue
      meta.node.opportunity.exhausted: 0.3  # Try exhausted nodes with new angle
      # Engagement & valence triggers — mid-engagement now contributes
      llm.engagement.low: 0.8               # Low engagement = strong trigger (was 1.2)
      llm.engagement.mid: 0.4               # Moderate engagement + fatigue = still revitalize (NEW)
      llm.engagement.high: -0.4             # Already engaged = not needed
      llm.valence.low: 0.5                  # Negative valence = shift gears
      # Global signals
      temporal.strategy_repetition_count: -0.3  # Penalize repetition (was +0.5 bug)
      # Node-level signals (Phase 3)
      graph.node.focus_streak.none: 0.8  # Fresh nodes
      graph.node.exhaustion_score.low: 0.5  # Avoid exhausted nodes

phases:
  early:
    description: "Initial exploration, building graph structure"
    signal_weights:
      explore: 1.5
      clarify: 1.2
      deepen: 0.5
      reflect: 0.2
    phase_bonuses:
      explore: 0.2  # Additive bonus to encourage exploration even with zero base score

  mid:
    description: "Building depth and connections"
    signal_weights:
      deepen: 1.3
      clarify: 0.8
      revitalize: 1.0             # Explicit mid-phase weight (was missing)
      explore: 0.6                # Reduced from 0.8 — mid phase should deepen, not explore
      reflect: 0.7
    phase_bonuses:
      deepen: 0.3  # Additive bonus to prioritize deepening in mid-phase

  late:
    description: "Validation and verification"
    signal_weights:
      reflect: 1.2
      revitalize: 1.2
      deepen: 0.5
      explore: 0.3
    phase_bonuses:
      reflect: 0.2  # Additive bonus to ensure reflection gets selected even with zero base score
      revitalize: 0.2  # Additive bonus for revitalize in late phase
