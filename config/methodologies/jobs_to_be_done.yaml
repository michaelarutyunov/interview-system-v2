# Jobs-to-be-Done Methodology Configuration
#
# JTBD explores what job users are trying to do, what triggers them,
# what alternatives they consider, and what obstacles they face.

method:
  name: jobs_to_be_done
  version: "2.0"
  goal: "Understand what jobs users are trying to accomplish and what motivates them"
  opening_bias: "Ask about a specific recent time they made a decision or change related to the topic."
  description: "Framework for understanding customer motivation and needs through job statements"

ontology:
  nodes:
    - name: job_statement
      level: 0
      terminal: false
      description: "Core functional or emotional job a customer is trying to accomplish"
      examples:
        - "get my daily caffeine fix"
        - "feel productive in the morning"
        - "socialize with colleagues"

    - name: job_context
      level: 0
      terminal: false
      description: "Situation or circumstances when the job arises"
      examples:
        - "when I'm rushing to work"
        - "when I'm working from home"
        - "when meeting clients"

    - name: job_trigger
      level: 0
      terminal: false
      description: "Event or stimulus that initiates the job"
      examples:
        - "feeling tired in the morning"
        - "anticipating a long meeting"
        - "hosting a gathering"

    - name: pain_point
      level: 0
      terminal: false
      description: "Obstacle or frustration in getting the job done"
      examples:
        - "coffee is too bitter"
        - "takes too long to prepare"
        - "upsets my stomach"

    - name: gain_point
      level: 0
      terminal: false
      description: "Desired outcome or benefit that makes the job worthwhile"
      examples:
        - "smooth, enjoyable taste"
        - "quick and convenient"
        - "feeling energized without jitters"

    - name: solution_approach
      level: 0
      terminal: false
      description: "Current or potential method for accomplishing the job"
      examples:
        - "using oat milk in coffee"
        - "buying coffee at a cafe"
        - "meal prepping"

    - name: emotional_job
      level: 1
      terminal: true
      description: "Emotional state or identity the customer seeks to achieve"
      examples:
        - "feel healthy and conscientious"
        - "project a professional image"
        - "treat myself with care"

    - name: social_job
      level: 1
      terminal: true
      description: "Social impression or relationship the customer wants to influence"
      examples:
        - "fit in with health-conscious peers"
        - "signal environmental values"
        - "avoid social awkwardness"

  edges:
    - name: occurs_in
      description: "Temporal or situational relationship between job and context"
      permitted_connections:
        - [job_statement, job_context]
        - [emotional_job, job_context]
        - [social_job, job_context]
        - [pain_point, job_context]      # Pain arises in a context
        - [gain_point, job_context]      # Gain matters in a context
        - [job_trigger, job_context]     # Triggers happen in contexts
        - [solution_approach, job_context]  # Solutions used in contexts

    - name: triggered_by
      description: "Causal relationship where a stimulus initiates or causes something"
      permitted_connections:
        - [job_statement, job_trigger]
        - [emotional_job, job_trigger]
        - [social_job, job_trigger]
        - [pain_point, pain_point]       # Pain cascades (clutter → distraction)
        - [pain_point, job_trigger]      # Pain triggered by event
        - [gain_point, job_trigger]      # Gain triggered by event

    - name: addresses
      description: "Solution approach resolves a pain point or enables a gain point"
      permitted_connections:
        - [solution_approach, pain_point]
        - [solution_approach, gain_point]
        - [solution_approach, job_statement]  # Solution accomplishes a job
        - [job_statement, emotional_job]
        - [job_statement, social_job]

    - name: conflicts_with
      description: "Something that prevents or undermines something else"
      permitted_connections:
        - [solution_approach, pain_point]
        - [pain_point, job_statement]
        - [pain_point, gain_point]       # Pain undermines a gain
        - [pain_point, solution_approach] # Pain blocks a solution
        - [solution_approach, solution_approach]  # Solutions can conflict with each other

    - name: enables
      description: "Something that makes something else more achievable or satisfying"
      permitted_connections:
        - [solution_approach, gain_point]
        - [gain_point, job_statement]
        - [gain_point, gain_point]       # Gain chains (saves time → productive)
        - [gain_point, emotional_job]    # Gain enables emotional outcome
        - [gain_point, social_job]       # Gain enables social outcome

    - name: supports
      description: "Something that contributes to or reinforces something else"
      permitted_connections:
        - [job_statement, emotional_job]
        - [job_statement, social_job]
        - [solution_approach, gain_point]    # Solution contributes to a gain
        - [solution_approach, job_statement] # Solution supports a job
        - [solution_approach, emotional_job] # Solution directly supports emotional outcome
        - [solution_approach, social_job]    # Solution directly supports social outcome
        - [gain_point, emotional_job]        # Gain supports emotional outcome
        - [gain_point, social_job]           # Gain supports social outcome

    - name: revises
      description: "Contradiction - newer belief or approach supersedes older one"
      permitted_connections:
        - ["*", "*"]

  extraction_guidelines:
    - "Listen for phrases indicating what the user is trying to accomplish ('I need to...', 'I want to...', 'The goal is...')"
    - "Identify the circumstances when the job becomes important ('when...', 'especially when...', 'in situations like...')"
    - "Extract pain points directly expressed ('frustrating that...', 'hate it when...', 'problem is...')"
    - "Extract gain points as positive outcomes ('love that...', 'great because...', 'important that...')"
    - "Distinguish between functional, emotional, and social jobs - often all three coexist"
    - "Map the current solution approach even if not explicitly stated"
    - "Connect jobs to their underlying emotional and social drivers"
    - "Look for trade-offs users make between competing jobs"
    - "Actively extract emotional jobs: look for identity statements, feeling words, aspirational language"
    - "Actively extract social jobs: look for peer references, social signals, reputation concerns"

  relationship_examples:
    explicit_job_statement:
      description: "Direct statement of what needs to be accomplished"
      example: "I need something that wakes me up but doesn't make me jittery"
      extraction: "job_statement('wake up without jitters') → addresses → pain_point('caffeine jitters')"

    implicit_context:
      description: "Context revealed through situation description"
      example: "When I have 8am meetings, I can't wait in line at the cafe"
      extraction: "job_statement('get morning coffee') → occurs_in → job_context('early morning meetings')"

    pain_trigger_chain:
      description: "Trigger reveals the pain point and the job together"
      example: "Dairy makes me feel bloated, especially before presentations"
      extraction: "job_trigger('before presentations') → triggered_by → job_statement('feel comfortable') conflicts_with pain_point('dairy bloating')"

    functional_supports_emotional:
      description: "Functional choice enables emotional outcome"
      example: "I choose oat milk because it aligns with my values"
      extraction: "solution_approach('oat milk') → supports → emotional_job('feel environmentally responsible')"

  extractability_criteria:
    extractable_contains:
      - "Goals or objectives the user wants to achieve"
      - "Frustrations, pain points, or obstacles"
      - "Positive outcomes or benefits they value"
      - "Situational context (when, where, with whom)"
      - "Current solutions or workarounds"
      - "Emotions or social considerations related to choices"
    non_extractable_contains:
      - "Simple yes/no responses"
      - "Acknowledgments ('okay', 'I see', 'right')"
      - "Questions back to the interviewer"
      - "Purely factual product descriptions without user context"
      - "Irrelevant tangents"

  concept_naming_convention: >
    Name each concept according to its node type role:
    phrase job_statements as jobs to be done,
    pain_points as frustrations or obstacles,
    gain_points as desired outcomes or benefits,
    solution_approaches as methods or actions,
    job_contexts as situations or circumstances,
    emotional_jobs as emotional states sought,
    social_jobs as social outcomes desired,
    job_triggers as initiating events.
    Use the examples in each node type description as naming models.

signals:
  graph:
    - graph.node_count
    - graph.orphan_count
    - graph.max_depth

  llm:
    - llm.response_depth
    - llm.valence
    - llm.certainty
    - llm.specificity
    - llm.engagement
    - llm.intellectual_engagement
    # Note: llm.global_response_trend is session-scoped and managed separately

  temporal:
    - temporal.strategy_repetition_count
    - temporal.turns_since_strategy_change

  meta:
    - meta.interview.phase
    - meta.conversation.saturation
    - meta.canonical.saturation
    # Note: meta.interview_progress is intentionally excluded from JTBD.
    # It is deprecated for this methodology and replaced by meta.conversation.saturation
    # and meta.canonical.saturation, which are information-velocity-based rather than
    # structural. Do not add it to signal_weights for any JTBD strategy.

strategies:
  # Strategy 1: Explore the situation (elaboration)
  - name: explore_situation
    description: "Understand the context and circumstances around when jobs arise"
    signal_weights:
      # Global signals
      llm.valence.mid: 0.5
      temporal.strategy_repetition_count: -0.7  # Symmetric repetition penalty (was -0.8)
      temporal.strategy_repetition_count.high: 0  # Reserved for future tuning
      # Engagement
      llm.engagement.mid: 0.4               # Moderate engagement = breadth OK
      # Response quality awareness — suppress exploration during declining quality
      llm.global_response_trend.shallowing: -0.4  # Don't explore when answers declining
      llm.global_response_trend.fatigued: -0.6    # Strongly suppress during fatigue
      # Node-level signals (Phase 3) — reduced weights to prevent node dominance
      graph.node.focus_streak.none: 0.6   # Fresh nodes (was 1.0)
      graph.node.focus_streak.medium: -0.4  # Penalize 2-3 turn over-focus
      graph.node.focus_streak.high: -0.7   # Strongly penalize 4+ turn over-focus
      graph.node.yield_stagnation.false: 0.5  # Nodes that yield (was 0.8)
      graph.node.exhaustion_score.low: 0.4  # Avoid exhausted nodes (was 0.7)

  # Strategy 2: Probe alternatives (probing)
  - name: probe_alternatives
    description: "Discover what other solutions or approaches the user has considered"
    signal_weights:
      # Global signals
      llm.specificity.high: 0.4
      # Engagement
      llm.engagement.mid: 0.3               # Moderate engagement = probing OK
      # Response depth — shallow answers suggest surface-level exploration still in play
      llm.response_depth.surface: 0.3       # Surface answers → probe alternatives
      llm.response_depth.shallow: 0.2       # Shallow answers → probe alternatives
      # Diversity — symmetric penalty to prevent monoculture
      temporal.strategy_repetition_count: -0.7  # Symmetric (was -0.8)
      temporal.strategy_repetition_count.high: 0  # Reserved for future tuning
      # Node-level signals (Phase 3)
      graph.node.is_orphan.true: 0.5       # was 1.0; reduced to prevent orphan boost dominance
      graph.node.exhaustion_score.low: 0.6  # Avoid exhausted nodes
      graph.node.focus_streak.none: 0.5    # Fresh nodes without prior focus
      graph.node.focus_streak.medium: -0.4  # Penalize 2-3 turn over-focus
      graph.node.focus_streak.high: -0.7    # Strongly penalize 4+ turn over-focus

  # Strategy 3: Dig into motivation (laddering)
  - name: dig_motivation
    description: "Probe deeper with 'why' questions to uncover underlying functional and emotional jobs"
    signal_weights:
      # Global signals — use actual category names (surface/shallow/moderate/deep)
      llm.response_depth.surface: 0.5    # Surface answers → dig deeper
      llm.response_depth.shallow: 0.4    # Shallow answers → dig deeper
      llm.response_depth.moderate: 0.15  # Even moderate answers can benefit from deepening
      llm.response_depth.deep: 0.3       # Deep answers → keep digging (chain is open)
      # graph.max_depth removed: maxes out at turn 2 in JTBD, creating permanent -0.4 drag
      # Engagement & valence safety checks — mid-engagement now contributes
      llm.engagement.high: 0.5              # Engaged = safe to dig deeper (was 0.7)
      llm.engagement.mid: 0.3               # Moderate engagement = still OK to dig (NEW)
      llm.engagement.low: -0.5              # Disengaged = avoid deepening
      llm.intellectual_engagement.high: 0.6  # Motivational reasoning revealed = prime laddering target
      llm.intellectual_engagement.mid: 0.3   # Some reasoning = worth probing further
      llm.valence.high: 0.4                 # Positive emotion = safe to probe
      # Response quality trend — dig when quality is declining
      llm.global_response_trend.shallowing: 0.4  # Shallow trend → try digging (NEW)
      # Diversity — asymmetric penalty to break dig_motivation dominance
      temporal.strategy_repetition_count: -1.5  # Override shared -0.7 — creates differential vs other strategies
      temporal.strategy_repetition_count.high: -1.0  # Severe penalty at 4-5 reps to break dominance
      # Node-level signals (Phase 3)
      graph.node.exhaustion_score.low: 0.3   # Reduced from 1.0 — was largest single contributor to dig_motivation dominance
      graph.node.focus_streak.low: 0.5       # Prefer nodes in first focus
      graph.node.focus_streak.medium: -0.4   # Penalize 2-3 turn over-focus
      graph.node.focus_streak.high: -0.8     # Strongly penalize 4+ turn over-focus

  # Strategy 4: Validate outcome (validation)
  - name: validate_outcome
    description: "Confirm understanding and check if we've captured the most important aspects"
    generates_closing_question: true
    focus_mode: summary
    signal_weights:
      # Global signals
      graph.max_depth: 0.5
      llm.response_depth.deep: 0.3       # Deep responses → validate
      llm.response_depth.moderate: 0.2   # Moderate responses → validate
      # Uncertainty/hedging triggers (Phase 5)
      llm.certainty.low: 1.0  # Trigger on high uncertainty
      llm.certainty.mid: 0.7  # Trigger on medium uncertainty
      meta.node.opportunity.probe_deeper: 0.6  # Extraction opportunity
      # Engagement trigger
      llm.engagement.low: 0.6               # Low engagement = validate & wrap
      # Diversity (lighter penalty — OK to repeat validation, but symmetric)
      temporal.strategy_repetition_count: -0.7  # Symmetric (was -0.2)
      temporal.strategy_repetition_count.high: 0  # Reserved for future tuning
      # Node-level signals (Phase 3)
      graph.node.has_outgoing.true: 0.8  # Well-connected nodes
      graph.node.focus_streak.high: 0.5  # Often-focused nodes
      technique.node.strategy_repetition.low: 0.3  # Avoid overusing same strategy
      # Saturation triggers (Phase 6)
      meta.conversation.saturation: 0.5  # High saturation = validate
      meta.canonical.saturation: 0.3     # Supportive metric

  # Strategy 5: Revitalize engagement (elaboration) - Phase 5
  - name: revitalize
    node_binding: none
    description: "Shift to fresh topics when response trend shows fatigue or repeated shallow answers"
    signal_weights:
      # Fatigue detection triggers (Phase 5)
      llm.global_response_trend.fatigued: 1.0  # Trigger on fatigue
      llm.global_response_trend.shallowing: 0.5  # Prevent fatigue
      meta.node.opportunity.exhausted: 0.3  # Try exhausted nodes with new angle
      # Engagement & valence triggers — mid-engagement now contributes
      llm.engagement.low: 0.8               # Low engagement = strong trigger (was 1.2)
      llm.engagement.mid: 0.4               # Moderate engagement + fatigue = still revitalize (NEW)
      llm.engagement.high: -0.4             # Already engaged = not needed
      llm.valence.low: 0.5                  # Negative valence = shift gears
      # Global signals - Symmetric penalty to prevent loops
      temporal.strategy_repetition_count: -0.7  # Symmetric (was -0.8)
      temporal.strategy_repetition_count.high: 0  # Reserved for future tuning
      temporal.turns_since_strategy_change: -0.6  # Penalty for staying too long
      # Node-level signals (Phase 3)
      graph.node.focus_streak.none: 0.8    # Fresh nodes
      graph.node.focus_streak.medium: -0.4  # Penalize 2-3 turn over-focus
      graph.node.focus_streak.high: -0.7    # Strongly penalize 4+ turn over-focus
      graph.node.exhaustion_score.low: 0.5  # Avoid exhausted nodes

  # Strategy 6: Uncover obstacles (probing)
  - name: uncover_obstacles
    description: "Identify pain points and frustrations that prevent jobs from being done well"
    signal_weights:
      # Global signals — negative valence is the primary trigger
      llm.valence.low: 0.9                  # Strong trigger on negative/critical responses (was 0.7)
      llm.valence.mid: 0.3                  # Neutral responses can also reveal obstacles
      llm.response_depth.moderate: 0.2      # Moderate answers about pains = probe more
      # Certainty: moderate certainty with negative valence = articulated frustration
      llm.certainty.mid: 0.2                # Respondent expressing doubt about solutions
      # Engagement — can surface obstacles even at mid engagement
      llm.engagement.mid: 0.3               # Moderate engagement = probing OK
      # Diversity — symmetric penalty to prevent lock
      temporal.strategy_repetition_count: -0.7  # Symmetric (was -0.5)
      temporal.strategy_repetition_count.high: 0  # Reserved for future tuning
      # Node-level signals (Phase 3) — reduced to prevent node dominance
      graph.node.is_orphan.true: 0.7       # Boost orphan nodes (was 1.0)
      graph.node.yield_stagnation.false: 0.5  # Nodes that yield (was 0.7)
      graph.node.exhaustion_score.low: 0.4  # Avoid exhausted nodes (was 0.6)
      graph.node.focus_streak.medium: -0.3  # Penalize 2-3 turn over-focus
      graph.node.focus_streak.high: -0.6    # Strongly penalize 4+ turn over-focus

  # Strategy 7: Clarify assumption (challenging)
  - name: clarify_assumption
    description: "Challenge a confident or specific claim to expose unstated assumptions or overgeneralizations. Use open-ended probes that invite elaboration rather than cross-examination or forced-choice questions."
    signal_weights:
      # Primary triggers — high certainty + high specificity = confident claim worth probing
      # Weights are moderate: clarify_assumption is a specialist, not a generalist.
      # It should win when certainty is high AND other strategies aren't competing,
      # not every turn an articulate respondent speaks.
      llm.certainty.high: 0.5        # Confident = probe-worthy (reduced from 0.8)
      llm.specificity.high: 0.3      # Concrete claim = target (reduced from 0.5)
      llm.response_depth.deep: 0.2   # Deep certain answer = worth surfacing (reduced from 0.3)
      # Self-doubt triggers — moderate certainty = surface the assumption
      llm.certainty.mid: 0.4         # Hedging/self-doubt (reduced from 0.6)
      llm.response_depth.moderate: 0.2  # Moderate depth + uncertainty
      # Engagement safety check
      llm.engagement.high: 0.2       # Engaged = will respond constructively
      llm.engagement.mid: 0.1        # Moderate engagement = gentle challenge OK
      llm.engagement.low: -0.5       # Disengaged = don't challenge
      # Diversity — strong brake; challenging is fatiguing if overused
      temporal.strategy_repetition_count: -1.5  # Asymmetric — high base needs strong brake
      temporal.strategy_repetition_count.high: -1.0  # Severe penalty at 4-5 reps
      # Node-level — prefer nodes the respondent has spoken confidently about
      graph.node.exhaustion_score.low: 0.5   # Fresh node = still something to challenge
      graph.node.focus_streak.low: 0.4       # First focus = just started engagement
      graph.node.focus_streak.medium: -0.4   # Penalize 2-3 turn over-focus
      graph.node.focus_streak.high: -0.7     # Strongly penalize 4+ turn over-focus

phases:
  early:
    description: "Initial exploration, building graph structure"
    signal_weights:
      explore_situation: 1.5
      probe_alternatives: 1.2
      dig_motivation: 0.5
      validate_outcome: 0.2
      uncover_obstacles: 0.3
    phase_bonuses:
      explore_situation: 0.2    # Additive bonus to encourage exploration even with zero base score
      probe_alternatives: 0.15  # Bonus to surface orphan alternatives early

  mid:
    description: "Building depth and connections"
    signal_weights:
      dig_motivation: 1.2        # Reduced from 1.4 — narrowing structural advantage over competitors
      probe_alternatives: 0.9    # Below 1.0: mid-phase should deepen, not probe
      uncover_obstacles: 1.3     # Boosted from 1.2 — compete when valence is low
      clarify_assumption: 1.3    # Boosted from 1.2 — fire on both certainty and self-doubt
      revitalize: 1.0
      explore_situation: 0.6
      validate_outcome: 0.5
    phase_bonuses:
      dig_motivation: 0.15       # Reduced from 0.3 — narrowing structural advantage over competitors
      probe_alternatives: 0.15   # Bonus to break out of single-node focus
      uncover_obstacles: 0.25    # Boosted — compete when dig_motivation is penalized
      clarify_assumption: 0.15   # Additive — ensure it fires on hedging turns

  late:
    description: "Validation and verification"
    signal_weights:
      validate_outcome: 1.5
      uncover_obstacles: 1.2
      dig_motivation: 0.5
      explore_situation: 0.3
    phase_bonuses:
      validate_outcome: 0.2  # Additive bonus to ensure validation gets selected
