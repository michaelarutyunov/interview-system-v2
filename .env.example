# ==============================================================================
# LLM Configuration - Dual Client Setup
# ==============================================================================

# Main LLM (for question generation)
# Uses higher-quality models like Claude Sonnet or GPT-4
LLM_MAIN_PROVIDER=anthropic
LLM_MAIN_MODEL=claude-sonnet-4-5-20250929
LLM_MAIN_TEMPERATURE=0.7
LLM_MAIN_MAX_TOKENS=1024
LLM_MAIN_TIMEOUT_SECONDS=30.0

# Light LLM (for scoring tasks)
# Uses faster, cheaper models like Claude Haiku or GPT-4o-mini
LLM_LIGHT_PROVIDER=anthropic
LLM_LIGHT_MODEL=claude-haiku-4-20250514
LLM_LIGHT_TEMPERATURE=0.3
LLM_LIGHT_MAX_TOKENS=512
LLM_LIGHT_TIMEOUT_SECONDS=15.0

# API Keys (shared for both clients in most cases)
ANTHROPIC_API_KEY=your-api-key-here
OPENAI_API_KEY=your-openai-key-here

# ==============================================================================
# Legacy Configuration (for backward compatibility)
# ==============================================================================
# These map to llm_main_* settings above
LLM_PROVIDER=anthropic
LLM_MODEL=claude-sonnet-4-5-20250929
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=1024
LLM_TIMEOUT_SECONDS=30.0

# ==============================================================================
# Database
# ==============================================================================
DATABASE_PATH=data/interview.db

# ==============================================================================
# Server
# ==============================================================================
DEBUG=true
HOST=127.0.0.1
PORT=8000
